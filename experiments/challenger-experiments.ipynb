{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482a0963",
   "metadata": {},
   "source": [
    "# Tarea 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2d27c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "import os, mlflow\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3fcb664d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/86265904456551', creation_time=1761101109923, experiment_id='86265904456551', last_update_time=1761662610718, lifecycle_stage='active', name='/Users/sarahbeltrang@gmail.com/nyc-taxi-experiments', tags={'mlflow.experiment.sourceName': '/Users/sarahbeltrang@gmail.com/nyc-taxi-experiments',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'sarahbeltrang@gmail.com',\n",
       " 'mlflow.ownerId': '76150295292949'}>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "EXPERIMENT_NAME = \"/Users/sarahbeltrang@gmail.com/nyc-taxi-experiments\"\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8746685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00e35695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe(\"C:/Users/sarah/apps/sem_5/pcd/nyc-taxi-predictions-2025/data/green_tripdata_2025-01.parquet\")\n",
    "df_val = read_dataframe(\"C:/Users/sarah/apps/sem_5/pcd/nyc-taxi-predictions-2025/data/green_tripdata_2025-02.parquet\")\n",
    "df_test = read_dataframe(\"C:/Users/sarah/apps/sem_5/pcd/nyc-taxi-predictions-2025/data/green_tripdata_2025-03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e491032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "780dea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# --- Ajustar DictVectorizer con training ---\n",
    "dv = DictVectorizer()\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# --- Transformar validation con el mismo dv ---\n",
    "X_val = preprocess(df_val, dv)\n",
    "\n",
    "# --- Transformar test con el mismo dv ---\n",
    "test_dicts = df_test[categorical + numerical].to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)\n",
    "X_test = preprocess(df_test, dv)\n",
    "\n",
    "# --- Opcional: convertir a DataFrame con nombres de columnas ---\n",
    "X_train_df = pd.DataFrame(X_train.toarray(), columns=dv.get_feature_names_out())\n",
    "X_val_df = pd.DataFrame(X_val.toarray(), columns=dv.get_feature_names_out())\n",
    "X_test_df = pd.DataFrame(X_test.toarray(), columns=dv.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06725bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "14f0633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f1fff6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e5d04164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaci칩n de training\n",
    "train_dicts = df_train[['PULocationID','DOLocationID','trip_distance']].copy()\n",
    "train_dicts['PU_DO'] = train_dicts['PULocationID'] + '_' + train_dicts['DOLocationID']\n",
    "train_dicts = train_dicts[['PU_DO','trip_distance']].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "y_train = df_train.duration.values\n",
    "\n",
    "# Transformaci칩n de validaci칩n usando el mismo dv\n",
    "val_dicts = df_val[['PULocationID','DOLocationID','trip_distance']].copy()\n",
    "val_dicts['PU_DO'] = val_dicts['PULocationID'] + '_' + val_dicts['DOLocationID']\n",
    "val_dicts = val_dicts[['PU_DO','trip_distance']].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_val = df_val.duration.values\n",
    "\n",
    "# Transformaci칩n de test usando el mismo dv\n",
    "test_dicts = df_test[['PULocationID','DOLocationID','trip_distance']].copy()\n",
    "test_dicts['PU_DO'] = test_dicts['PULocationID'] + '_' + test_dicts['DOLocationID']\n",
    "test_dicts = test_dicts[['PU_DO','trip_distance']].to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)\n",
    "y_test = df_test.duration.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e4924625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (46307, 4159)\n",
      "X_val shape:   (44218, 4159)\n",
      "X_test shape:  (48336, 4159)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:  \", X_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ec6be",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "25411aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import optuna\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b327fb",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94d23244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la funci칩n objetivo para Optuna - Gradient Boosting\n",
    "# ------------------------------------------------------------\n",
    "def objective_gb(trial: optuna.trial.Trial):\n",
    "    # Hiperpar치metros muestreados por Optuna en CADA trial\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"random_state\": 89,\n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"gradient_boosting\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predicci칩n y c치lculo del RMSE\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # RETURN para que Optuna minimice la m칠trica\n",
    "    # ------------------------------------------------------------\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f903d4",
   "metadata": {},
   "source": [
    "### Flujo de busqueda - GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a526670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 08:31:09,186] A new study created in memory with name: no-name-fdf35d27-074a-4abe-be81-bcc0f0609568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef73e46eaa4cbfb01d2357694d03f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:31:49 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:31:53,423] Trial 0 finished with value: 5.601293580469192 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.024057247038385035, 'subsample': 0.5484608547195821, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 0 with value: 5.601293580469192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run dapper-duck-49 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/5b6e5bc6c72f41959138fec9faa6a08c\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94840b77d5fc425eabdc3ced5c77cd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:32:31 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:32:35,676] Trial 1 finished with value: 5.787041863552104 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.014045078672943832, 'subsample': 0.7084819461637473, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 0 with value: 5.601293580469192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run masked-koi-472 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/606fa7c25d9a45d99348c83a7cdb146c\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2463a781637144fbb098ffdc6120c63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:33:16 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:33:21,951] Trial 2 finished with value: 5.860106950428719 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.01414158871279573, 'subsample': 0.7028502196908281, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 5.601293580469192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run orderly-frog-36 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/8acb243ad9694b0183915c8e771b4684\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a430c096c87d455891e5ef801b5f5549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:34:02 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run brawny-stoat-425 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/795fcea10cae402bbfcbc9e8fac04386\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 08:34:07,022] Trial 3 finished with value: 5.495399474408597 and parameters: {'n_estimators': 424, 'max_depth': 3, 'learning_rate': 0.07383111010702698, 'subsample': 0.5315492428909832, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 3 with value: 5.495399474408597.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617a4827a5fb4abf83342f51fc7e593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:34:50 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:34:54,443] Trial 4 finished with value: 5.56282755823677 and parameters: {'n_estimators': 413, 'max_depth': 3, 'learning_rate': 0.03236127724283307, 'subsample': 0.7673682361285976, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 3 with value: 5.495399474408597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run wise-bass-962 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/7ef3ad6e22a441858540b2dee38e98a8\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3309f3a751ae4350a721fb29509c57c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:35:27 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:35:31,146] Trial 5 finished with value: 5.692791512357716 and parameters: {'n_estimators': 206, 'max_depth': 3, 'learning_rate': 0.018286100901736085, 'subsample': 0.5520143019516879, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 5.495399474408597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run capable-gnat-311 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/7fe6f79cb88c4abcab2acecbc4a87fc4\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39a29c9098445e99ba516a976308553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:36:15 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:36:20,447] Trial 6 finished with value: 5.557905251253793 and parameters: {'n_estimators': 158, 'max_depth': 6, 'learning_rate': 0.020273135998556995, 'subsample': 0.9963519895207883, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 3 with value: 5.495399474408597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run bold-grouse-605 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/e63bb1c4b5564b4ea7d5a4046bc6fe28\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d9c8cefe724cdd9c005828a2fa8762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:37:03 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:37:07,371] Trial 7 finished with value: 5.468436274600439 and parameters: {'n_estimators': 474, 'max_depth': 3, 'learning_rate': 0.07083635184335539, 'subsample': 0.6590904307773464, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 7 with value: 5.468436274600439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run traveling-croc-29 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/62c5e1aaf7b7400aa63721f512400721\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c05cb50c7b4b6ca6648f28aaf45a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:37:37 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:37:42,376] Trial 8 finished with value: 5.437591039019735 and parameters: {'n_estimators': 406, 'max_depth': 7, 'learning_rate': 0.026706970597024548, 'subsample': 0.53280781534311, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 5.437591039019735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run placid-loon-382 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/48e8894e2f3742929e9a40027f93fdad\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb600e708759402ebb4a47375c7b8b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:38:11 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:38:15,853] Trial 9 finished with value: 5.5642126270182635 and parameters: {'n_estimators': 290, 'max_depth': 7, 'learning_rate': 0.012130083137673756, 'subsample': 0.6299145441235463, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: 5.437591039019735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run calm-bear-238 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/1b0f4edf203847feb101421f81369a5a\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811a53e50844425795542a8484618e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:38:46 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run Gradient Boosting Hyperparameter Optimization (Optuna) at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/0ead7f85fdf54fc3bdecf821ade07049\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FLUJO DE B칔SQUEDA Y ENTRENAMIENTO FINAL - GRADIENT BOOSTING\n",
    "# ============================================================\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=89)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimizaci칩n (n_trials = 10)\n",
    "#    - Cada trial ejecuta la funci칩n objetivo con un set distinto de hiperpar치metros\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la b칰squeda\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"Gradient Boosting Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective_gb, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar치metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    best_params[\"random_state\"] = 89\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"gradient_boosting\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Entrenar un modelo FINAL con los mejores hiperpar치metros\n",
    "    # --------------------------------------------------------\n",
    "    model = GradientBoostingRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Guardar artefactos adicionales (preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Guardar modelo final con signature\n",
    "    # --------------------------------------------------------\n",
    "    signature = infer_signature(X_val, y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        name=\"model\",\n",
    "        input_example=X_val[:5],\n",
    "        signature=signature\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac46b8",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cd1b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial: optuna.trial.Trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"random_state\": 89,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"random_forest\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # RETURN para que Optuna minimice la m칠trica\n",
    "    # ------------------------------------------------------------\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b042d",
   "metadata": {},
   "source": [
    "### Flujo de Busqueda - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e884bc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 08:38:50,689] A new study created in memory with name: no-name-efaacc4e-7477-429a-bbb8-e8fdc0cfbaf8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02948a59c4a46be9495f28e96639018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:39:15 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:39:35,222] Trial 0 finished with value: 8.12809579814196 and parameters: {'n_estimators': 275, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 8.12809579814196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run bald-trout-228 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/9ff06e07705e46d494b64d8f3fba437b\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744cba7c5e0444aeb90248b68d4f90fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:39:49 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:39:52,884] Trial 1 finished with value: 8.78498393108378 and parameters: {'n_estimators': 95, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 8.12809579814196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run likeable-squid-971 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/95dd9e5371b94afc9b2a75b868c0b357\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9af2c416b14147b677c809066e4a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:40:10 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:40:17,678] Trial 2 finished with value: 8.425142383859232 and parameters: {'n_estimators': 350, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 8.12809579814196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run bittersweet-pig-805 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/5d54c37686a247e4962309f044a6fd48\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad24f31f06514d2abcab9f71ad21a961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:40:39 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:40:51,526] Trial 3 finished with value: 8.299852114552086 and parameters: {'n_estimators': 413, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 8.12809579814196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run welcoming-pug-783 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/e3c531df6f244b99adb9355b21983210\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43e246cb8f24455b7ea3dbeb2a2ea14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:41:04 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:41:08,122] Trial 4 finished with value: 8.971627888038432 and parameters: {'n_estimators': 130, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 8.12809579814196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run unequaled-grouse-513 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/9f1f709f47994c0eae19438697408436\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5542432889e1468c964a8bfee0bdce38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:41:33 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:41:46,563] Trial 5 finished with value: 7.791217478989728 and parameters: {'n_estimators': 193, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 5 with value: 7.791217478989728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run agreeable-crow-973 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/2cf200a889714712a5e287446311f951\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec8344b489147a08d7ca616fa7f606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:42:27 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:42:52,482] Trial 6 finished with value: 8.633491924696177 and parameters: {'n_estimators': 406, 'max_depth': 31, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 7.791217478989728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run auspicious-hen-142 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/3665cc14839947949aceca642c9a2020\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57610b9968c8446195f9d4f3f79b1534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:43:08 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:43:12,996] Trial 7 finished with value: 8.187572402710689 and parameters: {'n_estimators': 75, 'max_depth': 16, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 5 with value: 7.791217478989728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run rare-croc-824 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/ec8f5872297d4a80a1f253864bcb7310\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad61b1b3426f413ea32a0d554df057dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:43:27 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:43:30,706] Trial 8 finished with value: 9.031513526366362 and parameters: {'n_estimators': 308, 'max_depth': 47, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': True}. Best is trial 5 with value: 7.791217478989728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run caring-penguin-862 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/a8598bca01784abc88cb9e8e87b7c3c7\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aa1be6b4a74d19be089df17742a310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:43:46 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-28 08:43:51,134] Trial 9 finished with value: 8.970877841342704 and parameters: {'n_estimators': 240, 'max_depth': 38, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 5 with value: 7.791217478989728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run traveling-lark-534 at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/40eec0f432a04c739c5af3057bb15e38\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675900eb22c5428aae9bcd1f95ca4944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 08:44:14 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run Random Forest Hyperparameter Optimization (Optuna) at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551/runs/07107074ae4e4cc0ad7201b6b3dda81d\n",
      "游빍 View experiment at: https://dbc-905d578f-b3ee.cloud.databricks.com/ml/experiments/86265904456551\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FLUJO DE B칔SQUEDA Y ENTRENAMIENTO FINAL - RANDOM FOREST\n",
    "# ============================================================\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=89)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimizaci칩n (n_trials = 10)\n",
    "#    - Cada trial ejecuta la funci칩n objetivo con un set distinto de hiperpar치metros\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la b칰squeda\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"Random Forest Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective_rf, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar치metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    best_params[\"random_state\"] = 89\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"random_forest\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Entrenar un modelo FINAL con los mejores hiperpar치metros\n",
    "    # --------------------------------------------------------\n",
    "    model = RandomForestRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Guardar artefactos adicionales (preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Guardar modelo final con signature\n",
    "    # --------------------------------------------------------\n",
    "    signature = infer_signature(X_val, y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        name=\"model\",\n",
    "        input_example=X_val[:5],\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f3484",
   "metadata": {},
   "source": [
    "## Registrar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "59c59994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"workspace.default.nyc-taxi-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2e1f367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끥 Champion Run encontrado:\n",
      "Run ID: 48e8894e2f3742929e9a40027f93fdad\n",
      "RMSE: 5.437591039019735\n",
      "Params: {'alpha': '0.9', 'ccp_alpha': '0.0', 'criterion': 'friedman_mse', 'init': 'None', 'learning_rate': '0.026706970597024548', 'loss': 'squared_error', 'max_depth': '7', 'max_features': 'None', 'max_leaf_nodes': 'None', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '6', 'min_samples_split': '4', 'min_weight_fraction_leaf': '0.0', 'n_estimators': '406', 'n_iter_no_change': 'None', 'random_state': '89', 'subsample': '0.53280781534311', 'tol': '0.0001', 'validation_fraction': '0.1', 'verbose': '0', 'warm_start': 'False'}\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Obtener el mejor run\n",
    "if len(runs) > 0:\n",
    "    best_run = runs[0]\n",
    "    print(\"游끥 Champion Run encontrado:\")\n",
    "    print(f\"Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"RMSE: {best_run.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {best_run.data.params}\")\n",
    "else:\n",
    "    print(\"丘멆잺 No se encontraron runs con m칠trica RMSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e3699dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = best_run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "339cd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.nyc-taxi-model' already exists. Creating a new version of this model...\n",
      "2025/10/28 08:44:30 WARNING mlflow.tracking._model_registry.fluent: Run with id 48e8894e2f3742929e9a40027f93fdad has no artifacts at artifact path 'model', registering model based on models:/m-c8fbdf448bda43d995b15d4e84cc7145 instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c1ecf4d533401eab56b193db8a3836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863fc436710f4381aae223c411d2fbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '6' of model 'workspace.default.nyc-taxi-model'.\n"
     ]
    }
   ],
   "source": [
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c38e3",
   "metadata": {},
   "source": [
    "## Asignar alias \"Challenger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e032274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4520ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = result.version\n",
    "new_alias = \"Challenger\"\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=new_alias,\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "321c7291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1761662675976, current_stage=None, deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description=('The model version 6 was transitioned to Challenger on 2025-10-28 '\n",
       " '08:44:43.303288'), last_updated_timestamp=1761662683770, metrics=[<Metric: dataset_digest='', dataset_name='', key='rmse', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662252093, value=5.437591039019735>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='root_mean_squared_error_unknown_dataset', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662251584, value=5.437591039019735>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_mean_absolute_error', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662247352, value=3.1825456714883>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_mean_squared_error', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662247352, value=23.660543929392094>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_r2_score', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662247352, value=0.6821343981775639>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_root_mean_squared_error', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662247352, value=4.864210514502029>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_score', model_id='m-c8fbdf448bda43d995b15d4e84cc7145', run_id='48e8894e2f3742929e9a40027f93fdad', step=0, timestamp=1761662248011, value=0.6821343981775639>], model_id='m-c8fbdf448bda43d995b15d4e84cc7145', name='workspace.default.nyc-taxi-model', params=[<LoggedModelParameter: key='min_impurity_decrease', value='0.0'>,\n",
       " <LoggedModelParameter: key='ccp_alpha', value='0.0'>,\n",
       " <LoggedModelParameter: key='warm_start', value='False'>,\n",
       " <LoggedModelParameter: key='max_depth', value='7'>,\n",
       " <LoggedModelParameter: key='min_samples_split', value='4'>,\n",
       " <LoggedModelParameter: key='max_leaf_nodes', value='None'>,\n",
       " <LoggedModelParameter: key='subsample', value='0.53280781534311'>,\n",
       " <LoggedModelParameter: key='min_weight_fraction_leaf', value='0.0'>,\n",
       " <LoggedModelParameter: key='validation_fraction', value='0.1'>,\n",
       " <LoggedModelParameter: key='tol', value='0.0001'>,\n",
       " <LoggedModelParameter: key='init', value='None'>,\n",
       " <LoggedModelParameter: key='max_features', value='None'>,\n",
       " <LoggedModelParameter: key='criterion', value='friedman_mse'>,\n",
       " <LoggedModelParameter: key='learning_rate', value='0.026706970597024548'>,\n",
       " <LoggedModelParameter: key='random_state', value='89'>,\n",
       " <LoggedModelParameter: key='n_estimators', value='406'>,\n",
       " <LoggedModelParameter: key='n_iter_no_change', value='None'>,\n",
       " <LoggedModelParameter: key='loss', value='squared_error'>,\n",
       " <LoggedModelParameter: key='alpha', value='0.9'>,\n",
       " <LoggedModelParameter: key='verbose', value='0'>,\n",
       " <LoggedModelParameter: key='min_samples_leaf', value='6'>], run_id='48e8894e2f3742929e9a40027f93fdad', run_link=None, source='models:/m-c8fbdf448bda43d995b15d4e84cc7145', status='READY', status_message='', tags={}, user_id='sarahbeltrang@gmail.com', version='6'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today()\n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b10ef6",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "59733b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2dcd3c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6499d672f84138be5e2d78e7ef59a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\apps\\sem_5\\pcd\\nyc-taxi-predictions-2025\\.venv\\Lib\\site-packages\\mlflow\\xgboost\\__init__.py:321: UserWarning: [11:21:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1511: Unknown file format: `xgb`. Using UBJSON (`ubj`) as a guess.\n",
      "  model.load_model(xgb_model_path)\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_version_uri = f\"models:/{model_name}@Champion\"\n",
    "\n",
    "champion_model = mlflow.pyfunc.load_model(model_version_uri)\n",
    "y_pred_champion = champion_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2955ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2101ea8d44b84ee6bbaa057c579a3c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_version_uri = f\"models:/{model_name}@Challenger\"\n",
    "\n",
    "challenger_model = mlflow.pyfunc.load_model(model_version_uri)\n",
    "y_pred_challenger = challenger_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e8c5e5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Champion en X_test: 6.383278117047989\n",
      "RMSE Challenger en X_test: 6.002214055571562\n"
     ]
    }
   ],
   "source": [
    "rmse_champion = np.sqrt(mean_squared_error(y_test, y_pred_champion))\n",
    "print(\"RMSE Champion en X_test:\", rmse_champion)\n",
    "\n",
    "rmse_challenger = np.sqrt(mean_squared_error(y_test, y_pred_challenger))\n",
    "print(\"RMSE Challenger en X_test:\", rmse_challenger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2bc45",
   "metadata": {},
   "source": [
    "Si se promovera el Challenger a Champion dado a que el rmse es menor por aprox. un 6%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce3506",
   "metadata": {},
   "source": [
    "![Pruebas](https://drive.google.com/uc?export=view&id=182pjlBuGfDjpfWzzVJTLitZovUvuFgIC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi-predictions-2025 (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
